{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2 - Clasificación\n",
    "# Universidad Europea de Madrid\n",
    "Inteligencia Artificial<br>\n",
    "Isabel Sutil<br>\n",
    "M31<br>\n",
    "Jorge Javier Castilla Coello<br>\n",
    "Geronimo Basso Sosa<br>\n",
    "Luis Cabello Casquete<br>\n",
    "Paula Sáenz de Santa María Diez<br>\n",
    "Ana Esteban González<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo en común utilizado por todos los apartados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 0\n",
    "Modificar el dataset para que cada vez que en \"prec\" se encuente el valor 0,0 se considere que no llueve, para los demas valores se va a considerar que si ha llovido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos el fichero necesario para analizar los modelos.\n",
    "ruta_archivo = 'valores-climatologicos.csv'\n",
    "dataframe = pd.read_table(ruta_archivo, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando una función lambda, para cada valor de ´prec´cambiamos su valor a 0 si la precipitación es 0\n",
    "cambiamos el valor a 1 si la precipitación es disitnto de 0. Además, creamos un mapeo de indivaticos de provincia para tener valores de tipo int en esa columna envez de strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe['prec'] = dataframe['prec'].apply(lambda x: '0' if x == 0.0 else '1') # 0 si no llovio, 1 si llovio.\n",
    "states = ['1387E', '1387', '1393', '1351', '1400', '1437O', '1473A', '1428', '1475X', '1505', '1484', '1484C', '1495']\n",
    "state_map = {state: idx for idx, state in enumerate(sorted(set(states)))}\n",
    "dataframe['indicativo'] = dataframe['indicativo'].apply(lambda x: state_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   indicativo  altitud  tmed prec  tmin  tmax  dir  velmedia  racha  presMax  \\\n",
      "0           2       98  16.9    0  12.0  21.8    1       3.1    8.3   1008.7   \n",
      "1           2       98  20.5    1  12.5  28.5   22       4.7   11.7   1008.5   \n",
      "2           2       98  21.4    0  17.6  25.1   22       2.2   10.3   1008.7   \n",
      "3           2       98  21.4    1  16.0  26.8   99       5.3   10.8   1009.4   \n",
      "4           2       98  18.6    0  15.7  21.6    4       3.9   11.7   1012.7   \n",
      "\n",
      "   presMin  \n",
      "0   1003.9  \n",
      "1   1005.5  \n",
      "2   1006.1  \n",
      "3   1005.4  \n",
      "4   1009.3  \n"
     ]
    }
   ],
   "source": [
    "# Visualización de las primeras filas del dataset.\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear el dataset de entrenamieno y validación, y además crear el cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 9228\n",
      "Tamaño del conjunto de validación: 2308\n"
     ]
    }
   ],
   "source": [
    "X = dataframe.drop('prec', axis=1)  # Features\n",
    "y = dataframe['prec']  # Variable de salida\n",
    "\n",
    "# División en 80/20 para entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir tamaños de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(X_val))\n",
    "\n",
    "# Crear conjuntos de entrenamiento y prueba\n",
    "conjunto_train = pd.concat([X_train, y_train], axis=1)\n",
    "conjunto_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Creamos dos conjuntos para poner las predicciones del train y test\n",
    "conjunto_train_eval = conjunto_train.copy()\n",
    "conjunto_validation_eval = conjunto_val.copy()\n",
    "\n",
    "# Método de control (k-fold cross-validation)\n",
    "metodo_control_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 5\n",
    "Análisis predictivo con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo SVM entrenado en el pliegue 1:\n",
      "Precisión en el step: 0.4118528703864548\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 2:\n",
      "Precisión en el step: 0.4117696112643129\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 3:\n",
      "Precisión en el step: 0.4118605905125994\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 4:\n",
      "Precisión en el step: 0.41113741623302824\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 5:\n",
      "Precisión en el step: 0.415592106845183\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 6:\n",
      "Precisión en el step: 0.41293566620072586\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 7:\n",
      "Precisión en el step: 0.4135353872482277\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 8:\n",
      "Precisión en el step: 0.4123104077261691\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 9:\n",
      "Precisión en el step: 0.41143558374176825\n",
      "\n",
      "Modelo SVM entrenado en el pliegue 10:\n",
      "Precisión en el step: 0.4121391590890713\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo SVM para regresión.\n",
    "svm_model = SVR()\n",
    "\n",
    "# Crear un pipeline con escalado de características\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalar las características\n",
    "    ('model', svm_model)            # Modelo SVM para regresión\n",
    "])\n",
    "\n",
    "# Obtener todos los modelos SVM entrenados durante la validación cruzada\n",
    "svm_models = [clone(pipeline).fit(X_train.iloc[train_idx], y_train.iloc[train_idx]) for train_idx, _ in metodo_control_cv.split(X_train, y_train)]\n",
    "\n",
    "# Imprimir información sobre el modelo\n",
    "for i, modelo in enumerate(svm_models):\n",
    "    print(f\"\\nModelo SVM entrenado en el pliegue {i + 1}:\")\n",
    "    precision = modelo.score(X_train, y_train)\n",
    "    print(\"Precisión en el step:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 6\n",
    "Análisis predictivo con Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 1:\n",
      "Precisión: 0.6689423493714781\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 2:\n",
      "Precisión: 0.6728435197225835\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 3:\n",
      "Precisión: 0.6673168617251842\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 4:\n",
      "Precisión: 0.6686172518422193\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 5:\n",
      "Precisión: 0.6712180320762896\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 6:\n",
      "Precisión: 0.6654746423927178\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 7:\n",
      "Precisión: 0.6702427394885132\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 8:\n",
      "Precisión: 0.6741439098396186\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 9:\n",
      "Precisión: 0.6736020806241872\n",
      "\n",
      "Modelo de Naive Bayes entrenado en el pliegue 10:\n",
      "Precisión: 0.6675335934113568\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de Naive Bayes.\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Crear un pipeline con escalado de características\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalar las características\n",
    "    ('model', naive_bayes_model)        # Modelo de regresión logística\n",
    "])\n",
    "\n",
    "# Obtener todos los modelos de Naive Bayes entrenados durante la validación cruzada\n",
    "naive_bayes_models = [clone(pipeline).fit(X_train.iloc[train_idx], y_train.iloc[train_idx]) for train_idx, _ in metodo_control_cv.split(X_train, y_train)]\n",
    "\n",
    "# Imprimir información sobre el modelo GaussianNB.\n",
    "for i, modelo in enumerate(naive_bayes_models):\n",
    "    print(f\"\\nModelo de Naive Bayes entrenado en el pliegue {i + 1}:\")\n",
    "    # Printing accuracy or other performance metrics\n",
    "    accuracy = modelo.score(X_train, y_train)\n",
    "    print(\"Precisión:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apartado 7\n",
    "Análisis comparativo de todos los modelos en train y en validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Modelos de Aprendizaje Automático\n",
    "\n",
    "En este análisis, comparamos cinco modelos de aprendizaje automático: Regresión Lineal, K-NN, Árbol de Decisión, SVM y Naive Bayes, utilizando un conjunto de datos de condiciones climatológicas. Cada modelo se evalúa en función de su precisión y características relevantes.\n",
    "\n",
    "### 1. Regresión Lineal\n",
    "- **Precisión**: Alrededor del 28.97% en promedio.\n",
    "- **Características**: Modelo simple y fácil de interpretar, pero muestra baja precisión para este conjunto de datos.\n",
    "- **Uso Ideal**: Mejor para relaciones lineales; parece no ser el más adecuado aquí debido a su baja precisión.\n",
    "\n",
    "### 2. K-NN (K-Nearest Neighbors)\n",
    "- **Precisión**: Alrededor del 47.89% en promedio.\n",
    "- **Características**: Modelo no paramétrico que es bueno para capturar relaciones no lineales.\n",
    "- **Uso Ideal**: Útil para conjuntos de datos donde las características similares predicen resultados similares; ofrece mejor precisión que la regresión lineal.\n",
    "\n",
    "### 3. Árbol de Decisión\n",
    "- **Precisión**: Entre 87.92% y 89.31%.\n",
    "- **Características**: Modelo altamente interpretable que puede capturar relaciones no lineales y complejas.\n",
    "- **Uso Ideal**: Excelente para problemas de clasificación y regresión; muestra la mayor precisión en este conjunto de datos.\n",
    "\n",
    "### 4. SVM (Máquinas de Vectores de Soporte)\n",
    "- **Precisión**: Alrededor del 41.24% en promedio.\n",
    "- **Características**: Efectivo en espacios de alta dimensión pero puede ser complejo de interpretar.\n",
    "- **Uso Ideal**: Adecuado para clasificación y regresión; sin embargo, muestra una precisión moderada en este caso.\n",
    "\n",
    "### 5. Naive Bayes\n",
    "- **Precisión**: Entre 66.89% y 67.48%.\n",
    "- **Características**: Basado en probabilidades y asume independencia entre predictores.\n",
    "- **Uso Ideal**: Bueno para clasificación; muestra una precisión moderadamente alta.\n",
    "\n",
    "### Conclusión\n",
    "El **Árbol de Decisión** demuestra ser el modelo más adecuado para este conjunto de datos, ofreciendo la mayor precisión. El **K-NN** también es una opción razonable. Sin embargo, la **Regresión Lineal**, **SVM** y **Naive Bayes** presentan una precisión más baja para este conjunto de datos en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
