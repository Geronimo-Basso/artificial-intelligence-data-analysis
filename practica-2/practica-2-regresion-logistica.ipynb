{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2 - Clasificación\n",
    "# Universidad Europea de Madrid\n",
    "Inteligencia Artificial<br>\n",
    "Isabel Sutil<br>\n",
    "M31<br>\n",
    "Jorge Javier Castilla Coello<br>\n",
    "Geronimo Basso Sosa<br>\n",
    "Luis Cabello Casquete<br>\n",
    "Paula Sáenz de Santa María Diez<br>\n",
    "Ana Esteban González<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo en común utilizado por todos los apartados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 0\n",
    "Modificar el dataset para que cada vez que en \"prec\" se encuente el valor 0,0 se considere que no llueve, para los demas valores se va a considerar que si ha llovido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos el fichero necesario para analizar los modelos.\n",
    "ruta_archivo = 'valores-climatologicos.csv'\n",
    "dataframe = pd.read_table(ruta_archivo, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando una función lambda, para cada valor de ´prec´cambiamos su valor a 0 si la precipitación es 0\n",
    "cambiamos el valor a 1 si la precipitación es disitnto de 0. Además, creamos un mapeo de indivaticos de provincia para tener valores de tipo int en esa columna envez de strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe['prec'] = dataframe['prec'].apply(lambda x: '0' if x == 0.0 else '1') # 0 si no llovio, 1 si llovio.\n",
    "states = ['1387E', '1387', '1393', '1351', '1400', '1437O', '1473A', '1428', '1475X', '1505', '1484', '1484C', '1495']\n",
    "state_map = {state: idx for idx, state in enumerate(sorted(set(states)))}\n",
    "dataframe['indicativo'] = dataframe['indicativo'].apply(lambda x: state_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   indicativo  altitud  tmed prec  tmin  tmax  dir  velmedia  racha  presMax  \\\n",
      "0           2       98  16.9    0  12.0  21.8    1       3.1    8.3   1008.7   \n",
      "1           2       98  20.5    1  12.5  28.5   22       4.7   11.7   1008.5   \n",
      "2           2       98  21.4    0  17.6  25.1   22       2.2   10.3   1008.7   \n",
      "3           2       98  21.4    1  16.0  26.8   99       5.3   10.8   1009.4   \n",
      "4           2       98  18.6    0  15.7  21.6    4       3.9   11.7   1012.7   \n",
      "\n",
      "   presMin  \n",
      "0   1003.9  \n",
      "1   1005.5  \n",
      "2   1006.1  \n",
      "3   1005.4  \n",
      "4   1009.3  \n"
     ]
    }
   ],
   "source": [
    "# Visualización de las primeras filas del dataset.\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear el dataset de entrenamieno y validación, y además crear el cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 9228\n",
      "Tamaño del conjunto de validación: 2308\n"
     ]
    }
   ],
   "source": [
    "X = dataframe.drop('prec', axis=1)  # Features\n",
    "y = dataframe['prec']  # Variable de salida\n",
    "\n",
    "# División en 80/20 para entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir tamaños de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(X_val))\n",
    "\n",
    "# Crear conjuntos de entrenamiento y prueba\n",
    "conjunto_train = pd.concat([X_train, y_train], axis=1)\n",
    "conjunto_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Creamos dos conjuntos para poner las predicciones del train y test\n",
    "conjunto_train_eval = conjunto_train.copy()\n",
    "conjunto_validation_eval = conjunto_val.copy()\n",
    "\n",
    "# Método de control (k-fold cross-validation)\n",
    "metodo_control_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2\n",
    "Análisis predictivo con Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 1:\n",
      "Precisión en el step: 0.2897079771771981\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 2:\n",
      "Precisión en el step: 0.28972270380803866\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 3:\n",
      "Precisión en el step: 0.2897645807853185\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 4:\n",
      "Precisión en el step: 0.28969591901494307\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 5:\n",
      "Precisión en el step: 0.2897227144081307\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 6:\n",
      "Precisión en el step: 0.2897278011997909\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 7:\n",
      "Precisión en el step: 0.2896186774824374\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 8:\n",
      "Precisión en el step: 0.2897401429317781\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 9:\n",
      "Precisión en el step: 0.28967344783597193\n",
      "\n",
      "Modelo de Regresion Lineal entrenado en el pliegue 10:\n",
      "Precisión en el step: 0.28973398250702564\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de Regresion Lineal.\n",
    "liner_regression_model = LinearRegression()\n",
    "\n",
    "# Crear un pipeline con escalado de características\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalar las características\n",
    "    ('model', liner_regression_model)        # Modelo de regresión logística\n",
    "])\n",
    "\n",
    "# Obtener todos los modelos de regresión lineal entrenados durante la validación cruzada\n",
    "liner_regression_models = [clone(pipeline).fit(X_train.iloc[train_idx], y_train.iloc[train_idx]) for train_idx, _ in metodo_control_cv.split(X_train, y_train)]\n",
    "\n",
    "# Imprimir información sobre el modelo\n",
    "for i, modelo in enumerate(liner_regression_models):\n",
    "    print(f\"\\nModelo de Regresion Lineal entrenado en el pliegue {i + 1}:\")\n",
    "    precision = modelo.score(X_train, y_train)\n",
    "    print(\"Precisión en el step:\", precision)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
