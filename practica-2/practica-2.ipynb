{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2 - Clasificación\n",
    "# Universidad Europea de Madrid\n",
    "Inteligencia Artificial<br>\n",
    "Isabel Sutil<br>\n",
    "M31<br>\n",
    "Jorge Javier Castilla Coello<br>\n",
    "Geronimo Basso Sosa<br>\n",
    "Luis Cabello Casquete<br>\n",
    "Paula Sáenz de Santa María Diez<br>\n",
    "Ana Esteban González<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 0\n",
    "Modificar el dataset para que cada vez que en \"prec\" se encuente el valor 0,0 se considere que no llueve, para los demas valores se va a considerar que si ha llovido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos el fichero necesario para analizar los modelos.\n",
    "ruta_archivo = 'valores-climatologicos.csv'\n",
    "fdata = pd.read_table(ruta_archivo, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizando una función lambda, para cada valor de ´prec´cambiamos su valor a No si la precipitación es 0\n",
    "# cambiamos el valor a Yes si la precipitación es disitnto de 0.\n",
    "fdata['prec'] = fdata['prec'].apply(lambda x: '0' if x == 0.0 else '1') # 0 si no llovio, 1 si llovio.\n",
    "states = ['1387E', '1387', '1393', '1351', '1400', '1437O', '1473A', '1428', '1475X', '1505', '1484', '1484C', '1495']\n",
    "# Creating a map where each unique state is assigned a unique number\n",
    "state_map = {state: idx for idx, state in enumerate(sorted(set(states)))}\n",
    "fdata['indicativo'] = fdata['indicativo'].apply(lambda x: state_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualización de las primeras filas del dataset.\n",
    "print(fdata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 1\n",
    "Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificamos si hay hay valores nulos que faltan en nuestro dataset.\n",
    "print(fdata.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertir la columna 'prec' de 'object' a 'categorical'\n",
    "fdata['prec'] = pd.Categorical(fdata['prec'])\n",
    "print(fdata.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 9228\n",
      "Tamaño del conjunto de validación: 2308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = fdata.drop('prec', axis=1)  # Features\n",
    "y = fdata['prec']  # Variable de salida\n",
    "\n",
    "# División en 80/20 para entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir tamaños de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear conjuntos de entrenamiento y prueba\n",
    "conjunto_train = pd.concat([X_train, y_train], axis=1)\n",
    "conjunto_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "\n",
    "# Creamos dos conjuntos para poner las predicciones del train y test\n",
    "conjunto_train_eval = conjunto_train.copy()\n",
    "conjunto_validation_eval = conjunto_val.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Método de control (k-fold cross-validation)\n",
    "metodo_control_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2\n",
    "Análisis predictivo con Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir el modelo de regresión logística\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Crear un pipeline con escalado de características\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Escalar las características\n",
    "    ('model', logreg_model)        # Modelo de regresión logística\n",
    "])\n",
    "\n",
    "\n",
    "# Realizar validación cruzada y obtener predicciones\n",
    "y_pred_cv = cross_val_predict(pipeline, X_train, y_train, cv=metodo_control_cv, method='predict_proba')\n",
    "y_val_pred_raw = cross_val_predict(pipeline, X_train, y_train, cv=metodo_control_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 1:\n",
      "Peso de X1 y X2: [[ 0.33349958 -0.01081902 -0.17954089  1.26919946 -1.65962565  0.25091472\n",
      "  -1.00652378  1.25473612  1.36654868 -1.46180238]]\n",
      "Precisión en el step: 0.7483745123537061\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 2:\n",
      "Peso de X1 y X2: [[ 0.33205953  0.00519328 -0.2208929   1.27317739 -1.60844928  0.24451122\n",
      "  -1.00455596  1.29385836  1.33012063 -1.42615725]]\n",
      "Precisión en el step: 0.7488079757260512\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 3:\n",
      "Peso de X1 y X2: [[ 0.33742835  0.00983295 -0.23606851  1.28722886 -1.62983584  0.24427861\n",
      "  -1.00377923  1.27455301  1.35808086 -1.46770763]]\n",
      "Precisión en el step: 0.7496749024707412\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 4:\n",
      "Peso de X1 y X2: [[ 0.31971982  0.0355363  -0.17692087  1.2620021  -1.66003405  0.23672905\n",
      "  -0.98912166  1.24567973  1.33647663 -1.44913777]]\n",
      "Precisión en el step: 0.7493498049414824\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 5:\n",
      "Peso de X1 y X2: [[ 0.32257916  0.01307198 -0.22861821  1.2569     -1.56828066  0.24911292\n",
      "  -0.97581523  1.24716525  1.38175583 -1.48449941]]\n",
      "Precisión en el step: 0.7488079757260512\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 6:\n",
      "Peso de X1 y X2: [[ 0.32454416  0.00633238 -0.26549789  1.27763097 -1.58281657  0.2391482\n",
      "  -1.02880363  1.28153703  1.36614524 -1.46221861]]\n",
      "Precisión en el step: 0.74913307325531\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 7:\n",
      "Peso de X1 y X2: [[ 0.32015537  0.01021695 -0.29655643  1.30213109 -1.56230304  0.23694795\n",
      "  -0.93446707  1.19543177  1.4532555  -1.53331485]]\n",
      "Precisión en el step: 0.7484828781967924\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 8:\n",
      "Peso de X1 y X2: [[ 3.31536279e-01 -2.74986762e-04 -1.95681698e-01  1.27688490e+00\n",
      "  -1.63194548e+00  2.51635701e-01 -9.87827528e-01  1.25320476e+00\n",
      "   1.31927268e+00 -1.42500150e+00]]\n",
      "Precisión en el step: 0.7478326831382748\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 9:\n",
      "Peso de X1 y X2: [[ 0.3298859   0.01265876 -0.25102163  1.31769558 -1.61723667  0.24322879\n",
      "  -1.03491076  1.30476757  1.35546188 -1.46577021]]\n",
      "Precisión en el step: 0.7493498049414824\n",
      "\n",
      "Modelo de regresión logística entrenado en el pliegue 10:\n",
      "Peso de X1 y X2: [[ 0.31859516  0.00893697 -0.32858966  1.30521679 -1.53302168  0.238527\n",
      "  -0.98584462  1.25770413  1.34148811 -1.43980264]]\n",
      "Precisión en el step: 0.7493498049414824\n"
     ]
    }
   ],
   "source": [
    "# Obtener todos los modelos de regresión logística entrenados durante la validación cruzada\n",
    "modelo_regresionLogistica_1 = [clone(pipeline).fit(X_train.iloc[train_idx], y_train.iloc[train_idx]) for train_idx, _ in metodo_control_cv.split(X_train, y_train)]\n",
    "\n",
    "# Obtener los coeficientes de cada modelo entrenado\n",
    "coeficientes_cv = [modelo.named_steps['model'].coef_ for modelo in modelo_regresionLogistica_1]\n",
    "\n",
    "# Imprimir información sobre el modelo\n",
    "for i, (modelo, coeficientes) in enumerate(zip(modelo_regresionLogistica_1, coeficientes_cv)):\n",
    "    print(f\"\\nModelo de regresión logística entrenado en el pliegue {i + 1}:\")\n",
    "    print(f\"Peso de X1 y X2:\", coeficientes)\n",
    "    precision = modelo.score(X_train, y_train)\n",
    "    print(\"Precisión en el step:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apartado 3\n",
    "Análisis predictivo con KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(KNeighborsClassifier(n_neighbors=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apartado 4\n",
    "Análisis predictivo con un árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 5\n",
    "Análisis predictivo con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 6\n",
    "Análisis predictivo con Naive Bayes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Realizamos imports necesario para útilizar en el modelo de predictivo de Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apartado 7\n",
    "Análisis comparativo de todos los modelos en train y en validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
